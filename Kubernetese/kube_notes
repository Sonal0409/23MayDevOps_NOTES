
Command to check number of nodes in cluster

$ kubectl get nodes


Schedule a pod in kube cluster

$ kubectl run pod1 --image nginx

similar to docker

 $ docker run --name c1 nginx

Check the pods is created or not in the cluster

 $ kubectl get pods

which Node is the pods scehduled:

$ kubectl get pods -o wide

similar to docker

docker ps -a

How did all this happen

to see all the details of the container:

$ kubectl describe pod pod1 | less

==> press q to come out of it 

similar to docker

docker inspect <containername>


Create a pod using object definition file:

apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx:1.14.2

Multi container POD
***************************
apiVersion: v1
kind: Pod
metadata:
  name: multi-container
spec:
  containers:
  - name: nginx
    image: nginx:1.10-alpine
  - name: alpine
    image: alpine:3.5
    command: ["watch", "wget", "-qO-", "localhost"]


$ kubectl create -f pod-definition.yml



*************************

ReplicaSet

---
apiVersion: apps/v1
kind: ReplicaSet
metadata:
 name: myrs
 labels:
  type: webserver
spec:
 replicas: 3
 selector:
  matchLabels:
   type: webserver
 template:
  metadata:
   name: mypod
   labels:
    type: webserver
  spec:
   containers:
    - name: myn1
      image: nginx
      
      
      
      Create replicaset
      
      $ kubectl create -f <name of the file.yml>
      
      Get all the object created in cluster
      
      $ kubectl get all
      
      get pods created in the cluster based on the labels
      
      $ kubectl get pods -l type=webserver
      
      Describe the details of the replicaSet
      
      $ kubectl describe replicaset myrs | less
      
      
      Deployment:
      *********************
      
      
      kind: Deployment
apiVersion: apps/v1
metadata:
  name: kubeserve
spec:
  replicas: 3
  minReadySeconds: 10 # wait for 45 sec before going to deploy next pod
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1  
      maxSurge: 1        # max number of pods to run for the deployment
  selector:
    matchLabels:
      app: kubeserve
  template:
    metadata:
      name: kubeserve
      labels:
        app: kubeserve
    spec:
      containers:
       - name: app
         image: leaddevops/kubeserve:v1
         
    $ kubectl create -f deployment1.yml
    
    $ kubectl get all
    
    $ kubectl set image deployment kubeserve app=leaddevops/kubeserve:v2
    
    $ kubectl describe deployment kubeserve | less
    
    $ kubectl set image deployment kubeserve app=leaddevops/kubeserve:v3
    
    $ $ kubectl describe deployment kubeserve | less
    
  565  kubectl rollout history deployment kubeserve
  566  kubectl rollout undo deployment kubeserve --to-revision=1
  567  kubectl describe deployment kubeserve | less


Horizontal Pod AutoScaller:

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
  labels:
    app: nginx
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      name: nginxpod
      labels:
        app: nginx
    spec:
      containers:
        - name: nginx
          image: nginx:latest
          resources:
            limits:
              cpu: 10m

$ kubectl create -f deployment2.yml

---

apiVersion: v1
kind: Service
metadata:
  name: nginx-svc
spec:
  type: ClusterIP  ## this is default if we do not type in service definition
  selector:
    app: nginx
  ports:
   - protocol: TCP
     port: 80
     targetPort: 80

$ kubectl create -f service2.yml
---

apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  name: nginx-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nginx
  minReplicas: 1
  maxReplicas: 10
  targetCPUUtilizationPercentage: 5
  
  $ kubectl create -f hpa.yml
  $ kubectl get all
  
  Load Genrator command:
  kubectl run -i --tty load-generator --rm --image=busybox --restart=Never -- /bin/sh -c "while sleep 0.01; do wget -q -O- http://10.8.0.237; done"
  
  
  ***************************************************************
  
  Persistent Volume:
  ************************
  apiVersion: v1
kind: PersistentVolume
metadata:
 name: block-pv
spec:
 storageClassName: manual
 capacity: 
  storage: 1Gi
 accessModes:
  - ReadWriteOnce
 hostPath:
  path: /tmp/data
  
  ***********************
  $ kubectl get pv
  $ kubectl create -f pv.yml
  
  *****************
  vim pvc.yml
  
  apiVersion: v1
kind: PersistentVolumeClaim
metadata:
 name: pvc
spec:
 storageClassName: manual
 accessModes:
  - ReadWriteOnce
 resources:
  requests:
   storage: 1Gi
   
   $ kubectl get pvc
   $ kubectl create -f pvc.yml
   
   **************
   
   vim pod-pvc.yml
   
   apiVersion: v1
kind: PersistentVolumeClaim
metadata:
 name: pvc
spec:
 storageClassName: manual
 accessModes:
  - ReadWriteOnce
 resources:
  requests:
   storage: 1Gi
   
   ********
   $ kubectl get pods
   kubectl create -f pod-pvc.yml
  
  
  
  # kubectl get configmap
 
 # kubectl create configmap dev-config --from-literal=app.mem=2048m
 
 # kubectl get configmap
 
 # kubectl get configmap dev-config -o yaml
 # vim dev.properties
app.env:dev
app.mem=2048m
app.properties=dev.env.url
:wq!

# kubectl create configmap dev-config1 --from-file=dev.properties
# kubectl get configmap
# kubectl get configmap dev-config1 -o yaml

Use configmap for a pod

vim pod-configmap.yml

kind: Pod
apiVersion: v1
metadata:
 name: pod-configmap
spec:
 containers:
  - image: nginx
    name: c1
    volumeMounts:
     - name: config-volume
       mountPath: /etc/config
 volumes:
  - name: config-volume
    configMap:
     name: dev-config1
 restartPolicy: Never
 
 :wq!
 
 # kubectl apply -f pod-configmap.yml
 # kubectl exec -it pod-configmap bash
 # cd /etc/config
 
 you will find the dev.properties file and configurations
 
 Edit the configMAP
 
 kubectl edit configmap -n <namespace> <configMapName> -o yaml

This opens up a vim editor with the configmap in yaml format. Now simply edit it and save it.
